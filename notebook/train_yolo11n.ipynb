{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c592070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ede9c9",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77bbff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix NumPy 2.x compatibility FIRST\n",
    "!pip install ultralytics --quiet\n",
    "!pip install \"numpy<2\" --quiet\n",
    "\n",
    "print(\"‚úÖ Ultralytics installed successfully!\")\n",
    "print(\"‚úÖ NumPy downgraded to 1.x for compatibility!\")\n",
    "print(\"‚ÑπÔ∏è  Using Kaggle pre-installed packages (torch, cv2, etc.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Verify GPU\n",
    "print(\"=\"*60)\n",
    "print(\"üîß SYSTEM INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU Memory: {gpu_mem:.1f} GB\")\n",
    "    \n",
    "    # Recommend batch size based on GPU memory\n",
    "    if gpu_mem >= 15:  # P100 16GB\n",
    "        recommended_batch = 16\n",
    "    elif gpu_mem >= 10:\n",
    "        recommended_batch = 12\n",
    "    else:\n",
    "        recommended_batch = 8\n",
    "    print(f\"\\n‚úÖ Recommended batch size: {recommended_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a09ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N - FIX C·ª®NG CHO KAGGLE\n",
    "# ============================================\n",
    "\n",
    "DATASET_PATH = \"/kaggle/input/waste-organic-inorganic-reclycable-yolov8/Final_dataset\"\n",
    "OUTPUT_DIR = \"/kaggle/working\"\n",
    "\n",
    "# Verify dataset exists\n",
    "print(\"=\"*60)\n",
    "print(\"üìÅ DATASET VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    print(f\"‚úÖ Dataset found at: {DATASET_PATH}\")\n",
    "    \n",
    "    # Count images in each split\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        img_path = os.path.join(DATASET_PATH, split, 'images')\n",
    "        if os.path.exists(img_path):\n",
    "            count = len([f for f in os.listdir(img_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            print(f\"   {split}: {count} images\")\n",
    "else:\n",
    "    print(f\"‚ùå Dataset NOT found at: {DATASET_PATH}\")\n",
    "    print(\"Please check the dataset path!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4738124f",
   "metadata": {},
   "source": [
    "## 2. Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5acd920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40 waste classes - c·∫≠p nh·∫≠t ƒë√∫ng v·ªõi dataset\n",
    "CLASS_NAMES = {\n",
    "    # Organic (0-32) - 33 classes\n",
    "    0: 'Apple', 1: 'Apple-core', 2: 'Apple-peel', 3: 'Bone', 4: 'Bone-fish',\n",
    "    5: 'Bread', 6: 'Bun', 7: 'Egg', 8: 'Egg-hard', 9: 'Egg-scramble',\n",
    "    10: 'Egg-shell', 11: 'Egg-steam', 12: 'Egg-yolk', 13: 'Fish', 14: 'Meat',\n",
    "    15: 'Mussel', 16: 'Mussel-shell', 17: 'Noodle', 18: 'Orange', 19: 'Orange-peel',\n",
    "    20: 'Other-waste', 21: 'Pancake', 22: 'Pasta', 23: 'Pear', 24: 'Pear-core',\n",
    "    25: 'Pear-peel', 26: 'Potato', 27: 'Rice', 28: 'Shrimp', 29: 'Shrimp-shell',\n",
    "    30: 'Tofu', 31: 'Tomato', 32: 'Vegetable',\n",
    "    # Inorganic (33-34) - 2 classes\n",
    "    33: 'plastic_bag', 34: 'styrofoam',\n",
    "    # Recyclable (35-39) - 5 classes\n",
    "    35: 'Cardboard', 36: 'Glass', 37: 'Metal', 38: 'Paper', 39: 'Plastic'\n",
    "}\n",
    "\n",
    "# Convert dict to list for YOLO\n",
    "CLASS_NAMES_LIST = [CLASS_NAMES[i] for i in range(len(CLASS_NAMES))]\n",
    "\n",
    "print(f\"\\nüìä CLASS DISTRIBUTION:\")\n",
    "print(f\"   Total classes: {len(CLASS_NAMES)}\")\n",
    "print(f\"   Organic (0-32): 33 classes\")\n",
    "print(f\"   Inorganic (33-34): 2 classes\")\n",
    "print(f\"   Recyclable (35-39): 5 classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b624e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml for training\n",
    "data_yaml = {\n",
    "    'path': DATASET_PATH,\n",
    "    'train': 'train/images',\n",
    "    'val': 'valid/images', \n",
    "    'test': 'test/images',\n",
    "    'nc': len(CLASS_NAMES),\n",
    "    'names': CLASS_NAMES_LIST\n",
    "}\n",
    "\n",
    "yaml_path = f\"{OUTPUT_DIR}/data.yaml\"\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
    "\n",
    "print(f\"‚úÖ Created data.yaml at: {yaml_path}\")\n",
    "\n",
    "# Verify yaml content\n",
    "print(\"\\nüìÑ data.yaml content:\")\n",
    "with open(yaml_path, 'r') as f:\n",
    "    print(f.read()[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc928d27",
   "metadata": {},
   "source": [
    "## 3. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e8be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    \"\"\"Gi·∫£i ph√≥ng GPU v√† RAM memory\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # Print current memory status\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        free = (torch.cuda.get_device_properties(0).total_memory / 1e9) - reserved\n",
    "        print(f\"‚úÖ Memory cleared! Free: {free:.2f}GB\")\n",
    "\n",
    "# Clear memory before training\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d901f06",
   "metadata": {},
   "source": [
    "## 4. üöÄ Train YOLO11n - Optimized Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üöÄ TRAINING YOLO11n - OPTIMIZED FOR P100\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìã Training Configuration:\")\n",
    "print(\"   Model: YOLO11n (latest architecture)\")\n",
    "print(\"   Epochs: 150\")\n",
    "print(\"   Batch size: 16\")\n",
    "print(\"   Image size: 640\")\n",
    "print(\"   Optimizer: AdamW\")\n",
    "print(\"   Learning rate: 0.001 ‚Üí 0.0001 (cosine)\")\n",
    "print(\"   Augmentation: Strong (mosaic, mixup, hsv, flip)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load pretrained YOLO11n\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# ============================================\n",
    "# TRAINING CONFIGURATION - OPTIMIZED FOR P100\n",
    "# ============================================\n",
    "results = model.train(\n",
    "    # === Data Configuration ===\n",
    "    data=yaml_path,\n",
    "    \n",
    "    # === Training Duration ===\n",
    "    epochs=100,              # Train longer for better model\n",
    "    patience=25,             # Early stopping patience\n",
    "    \n",
    "    # === Batch & Image Size ===\n",
    "    batch=16,                # Optimal for P100 16GB\n",
    "    imgsz=640,               # Standard YOLO size\n",
    "    \n",
    "    # === Hardware ===\n",
    "    device=0,                # GPU 0\n",
    "    workers=4,               # Data loading workers\n",
    "    \n",
    "    # === Optimizer Settings ===\n",
    "    optimizer='AdamW',       # Best optimizer for transformers\n",
    "    lr0=0.001,               # Initial learning rate\n",
    "    lrf=0.01,                # Final LR = lr0 * lrf = 0.00001\n",
    "    momentum=0.937,          # SGD momentum/Adam beta1\n",
    "    weight_decay=0.0005,     # L2 regularization\n",
    "    \n",
    "    # === Warmup Settings ===\n",
    "    warmup_epochs=5,         # Longer warmup for stability\n",
    "    warmup_momentum=0.8,\n",
    "    warmup_bias_lr=0.1,\n",
    "    \n",
    "    # === Loss Weights (tuned for waste detection) ===\n",
    "    box=7.5,                 # Box loss weight\n",
    "    cls=0.5,                 # Classification loss weight\n",
    "    dfl=1.5,                 # Distribution focal loss weight\n",
    "    \n",
    "    # === Data Augmentation (STRONG) ===\n",
    "    hsv_h=0.015,             # Hue augmentation\n",
    "    hsv_s=0.7,               # Saturation augmentation\n",
    "    hsv_v=0.4,               # Value augmentation\n",
    "    degrees=10.0,            # Rotation\n",
    "    translate=0.1,           # Translation\n",
    "    scale=0.5,               # Scale augmentation\n",
    "    shear=2.0,               # Shear\n",
    "    perspective=0.0001,      # Perspective\n",
    "    flipud=0.5,              # Vertical flip\n",
    "    fliplr=0.5,              # Horizontal flip\n",
    "    bgr=0.0,                 # BGR augmentation\n",
    "    mosaic=1.0,              # Mosaic augmentation\n",
    "    mixup=0.15,              # Mixup augmentation\n",
    "    copy_paste=0.1,          # Copy-paste augmentation\n",
    "    erasing=0.4,             # Random erasing\n",
    "    crop_fraction=1.0,       # Crop fraction\n",
    "    \n",
    "    # === Memory & Performance ===\n",
    "    cache=False,             # Don't cache to save RAM\n",
    "    amp=True,                # Mixed precision training\n",
    "    \n",
    "    # === Output Settings ===\n",
    "    project=f\"{OUTPUT_DIR}/runs\",\n",
    "    name=\"yolo11n_waste_optimized\",\n",
    "    exist_ok=True,\n",
    "    pretrained=True,\n",
    "    save=True,\n",
    "    save_period=20,          # Save checkpoint every 20 epochs\n",
    "    plots=True,\n",
    "    val=True,\n",
    "    \n",
    "    # === Advanced Settings ===\n",
    "    cos_lr=True,             # Cosine learning rate scheduler\n",
    "    close_mosaic=10,         # Disable mosaic last 10 epochs\n",
    "    label_smoothing=0.1,     # Label smoothing for better generalization\n",
    "    nbs=64,                  # Nominal batch size for loss normalization\n",
    "    overlap_mask=True,\n",
    "    mask_ratio=4,\n",
    "    dropout=0.1,             # Dropout for regularization\n",
    "    seed=42,                 # Reproducibility\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
